{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, List, Optional\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Gymnasium\n",
    "import gymnasium as gym\n",
    "from gymnasium import error, spaces\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from gymnasium.utils import EzPickle\n",
    "\n",
    "\n",
    "# Box2D\n",
    "from gymnasium.envs.box2d.bipedal_walker import BipedalWalker, BipedalWalkerHardcore\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box2D Imports for Physics Simulations\n",
    "##### imports several classes from Box2D, a physics library for 2D simulations\n",
    "##### The imported classes are used to define shapes, contact behaviors, etc\n",
    "##### Physical Properties Necessary for the Simulation\n",
    "###### If the import fails, an error is thrown indicating that Box2D needs to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import Box2D\n",
    "    from Box2D.b2 import (\n",
    "        circleShape,\n",
    "        contactListener,\n",
    "        edgeShape,\n",
    "        fixtureDef,\n",
    "        polygonShape,\n",
    "        revoluteJointDef,\n",
    "    )\n",
    "except ImportError as e:\n",
    "    raise DependencyNotInstalled(\n",
    "        \"Box2D is not installed, run `pip install gymnasium[box2d]`\"\n",
    "    ) from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `RewardModifierWrapper` is a class that wraps (or \"wraps\") your reinforcement learning environment to modify the reward the agent receives after each action. The purpose of this wrapper is to allow you to customize the reward based on specific criteria without changing the original environment code.\n",
    "\n",
    "#### Here is a detailed explanation of how the wrapper modifies the reward:\n",
    "\n",
    "####        1. **Initialization (`__init__`)**: Allows the wrapper to access and manipulate the functionality of the original environment.\n",
    "\n",
    "####        2. **`step`** method: This method is called with each agent action. It performs the action in the original environment and captures the result, which includes the resulting state, the reward, an indication of whether the episode is finished (`done`), and any additional information (`info`).\n",
    "\n",
    "####        3. **Modify Reward**: The implemented penalty logic focuses on penalizing \"sudden movements\". This is done by calculating the absolute difference between the current action and the previous action (using `np.diff` and `np.abs`). The penalty is proportional to the sum of these differences. Thus, if the agent changes its actions quickly from one step to another, it receives a penalty, reducing the total reward.\n",
    "\n",
    "####        4. **Return Modified Results**: Finally, the `step` method returns the state, modified reward, `done` value and information, along with any additional values returned by the environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Wrapper\n",
    "#### Attempt 1: penalidade_movimento_brusco = 0.002\n",
    "#### Attempt 2: penalidade_movimento_brusco = 0.003 \n",
    "#### Attempt 3: penalidade_movimento_brusco = 0.004\n",
    "#### Default: penalidade_movimento_brusco = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "action ['+0.00', '+0.00', '+0.00', '+0.00']\n",
      "step 0 total_reward -0.08\n",
      "hull ['-0.01', '+0.00', '-0.00', '-0.00']\n",
      "leg0 ['+0.44', '+0.07', '+0.11', '-0.08', '+1.00']\n",
      "leg1 ['+0.34', '+0.07', '+0.12', '-0.09', '+1.00']\n",
      "\n",
      "action ['+0.03', '-0.01', '-0.02', '+0.42']\n",
      "step 20 total_reward -1.01\n",
      "hull ['-0.06', '+0.01', '+0.01', '-0.01']\n",
      "leg0 ['+1.01', '-0.13', '-0.57', '-0.02', '+0.00']\n",
      "leg1 ['+0.51', '-0.06', '-0.08', '-0.03', '+0.00']\n",
      "\n",
      "action ['+0.03', '-0.01', '-0.01', '+0.43']\n",
      "step 40 total_reward -1.16\n",
      "hull ['-0.03', '+0.00', '+0.02', '-0.00']\n",
      "leg0 ['+1.00', '+0.02', '-0.59', '-0.01', '+0.00']\n",
      "leg1 ['+0.48', '-0.02', '-0.11', '-0.00', '+0.00']\n",
      "\n",
      "action ['+0.04', '-0.01', '-0.02', '+0.42']\n",
      "step 60 total_reward -1.20\n",
      "hull ['-0.03', '-0.00', '+0.04', '-0.00']\n",
      "leg0 ['+0.99', '-0.01', '-0.59', '+0.00', '+0.00']\n",
      "leg1 ['+0.43', '-0.04', '-0.11', '+0.00', '+0.00']\n",
      "\n",
      "action ['+0.05', '-0.01', '-0.01', '+0.41']\n",
      "step 80 total_reward -0.58\n",
      "hull ['-0.03', '+0.00', '+0.11', '-0.01']\n",
      "leg0 ['+0.97', '-0.00', '-0.57', '+0.02', '+0.00']\n",
      "leg1 ['+0.29', '-0.14', '-0.08', '+0.02', '+0.00']\n",
      "\n",
      "action ['+0.10', '-0.05', '+0.10', '+0.76']\n",
      "step 100 total_reward +0.57\n",
      "hull ['+0.16', '+0.05', '+0.31', '+0.06']\n",
      "leg0 ['+0.56', '-0.46', '-0.46', '-0.92', '+0.00']\n",
      "leg1 ['-0.45', '-1.36', '+0.43', '+1.01', '+0.00']\n",
      "\n",
      "action ['-0.02', '+0.47', '+0.21', '+0.17']\n",
      "step 120 total_reward +3.62\n",
      "hull ['-0.01', '-0.03', '+0.26', '+0.01']\n",
      "leg0 ['+0.40', '-0.15', '-0.15', '+0.13', '+0.00']\n",
      "leg1 ['+0.38', '+1.00', '-0.63', '-0.00', '+0.00']\n",
      "\n",
      "action ['+0.40', '-1.00', '-0.02', '+0.96']\n",
      "step 140 total_reward +7.10\n",
      "hull ['-0.02', '-0.02', '+0.27', '-0.01']\n",
      "leg0 ['-0.02', '+1.00', '-0.06', '-1.00', '+0.00']\n",
      "leg1 ['+0.82', '-0.05', '-0.32', '-0.16', '+0.00']\n",
      "\n",
      "action ['-0.01', '-0.08', '-0.01', '+0.28']\n",
      "step 160 total_reward +9.61\n",
      "hull ['-0.05', '+0.03', '+0.28', '+0.01']\n",
      "leg0 ['+1.10', '-0.05', '-0.63', '+0.00', '+0.00']\n",
      "leg1 ['+0.32', '-0.61', '-0.10', '+0.17', '+0.00']\n",
      "\n",
      "action ['+0.04', '+0.54', '+0.48', '-0.69']\n",
      "step 180 total_reward +12.48\n",
      "hull ['+0.13', '-0.03', '+0.30', '+0.00']\n",
      "leg0 ['+0.51', '-0.10', '-0.18', '-0.05', '+1.00']\n",
      "leg1 ['-0.07', '+1.00', '-0.32', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.02', '+0.13', '-0.48', '+1.00']\n",
      "step 200 total_reward +17.09\n",
      "hull ['-0.05', '+0.03', '+0.40', '-0.04']\n",
      "leg0 ['-0.02', '-0.90', '+0.21', '+0.43', '+1.00']\n",
      "leg1 ['+1.04', '-0.68', '-0.35', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.02', '-0.26', '-0.06', '+0.41']\n",
      "step 220 total_reward +20.01\n",
      "hull ['-0.12', '-0.02', '+0.30', '+0.04']\n",
      "leg0 ['+0.80', '+0.93', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.57', '-0.33', '-0.24', '+0.15', '+1.00']\n",
      "\n",
      "action ['+0.02', '+0.81', '+0.50', '-1.00']\n",
      "step 240 total_reward +24.32\n",
      "hull ['+0.07', '-0.01', '+0.35', '-0.00']\n",
      "leg0 ['+0.66', '-0.23', '-0.32', '-0.08', '+1.00']\n",
      "leg1 ['-0.16', '+1.00', '-0.08', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.05', '+0.00', '-0.20', '+0.70']\n",
      "step 260 total_reward +28.95\n",
      "hull ['+0.05', '+0.05', '+0.43', '-0.06']\n",
      "leg0 ['-0.22', '-1.00', '+0.27', '+0.37', '+0.00']\n",
      "leg1 ['+0.81', '-1.00', '-0.04', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.01', '-0.22', '-0.06', '+0.45']\n",
      "step 280 total_reward +31.99\n",
      "hull ['-0.10', '-0.02', '+0.28', '+0.03']\n",
      "leg0 ['+0.78', '+0.96', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.61', '-0.21', '-0.24', '+0.10', '+0.00']\n",
      "\n",
      "action ['+0.08', '+0.40', '+0.93', '-1.00']\n",
      "step 300 total_reward +36.12\n",
      "hull ['+0.09', '+0.01', '+0.37', '-0.02']\n",
      "leg0 ['+0.59', '-0.28', '-0.06', '-0.25', '+1.00']\n",
      "leg1 ['-0.40', '+0.27', '+0.28', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.03', '+0.20', '-0.06', '-0.02']\n",
      "step 320 total_reward +40.68\n",
      "hull ['-0.05', '+0.01', '+0.42', '-0.04']\n",
      "leg0 ['+0.06', '-0.69', '+0.14', '+0.33', '+1.00']\n",
      "leg1 ['+1.04', '+0.48', '-0.45', '+0.14', '+0.00']\n",
      "\n",
      "action ['+0.25', '+0.02', '-0.03', '+0.65']\n",
      "step 340 total_reward +43.95\n",
      "hull ['-0.04', '-0.02', '+0.22', '+0.02']\n",
      "leg0 ['+0.30', '+1.00', '-0.70', '-0.83', '+0.00']\n",
      "leg1 ['+0.76', '-0.05', '-0.28', '-0.02', '+1.00']\n",
      "\n",
      "action ['+0.04', '-0.03', '-0.02', '+0.32']\n",
      "step 360 total_reward +46.39\n",
      "hull ['-0.06', '+0.02', '+0.25', '+0.00']\n",
      "leg0 ['+1.01', '-0.14', '-0.60', '+0.00', '+0.00']\n",
      "leg1 ['+0.31', '-0.52', '-0.07', '+0.12', '+1.00']\n",
      "\n",
      "action ['+0.03', '+0.48', '+0.38', '-0.32']\n",
      "step 380 total_reward +49.40\n",
      "hull ['+0.10', '-0.02', '+0.33', '+0.00']\n",
      "leg0 ['+0.39', '-0.26', '-0.16', '+0.06', '+1.00']\n",
      "leg1 ['+0.13', '+1.00', '-0.52', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.42', '-1.00', '-0.01', '+0.86']\n",
      "step 400 total_reward +54.22\n",
      "hull ['+0.00', '-0.02', '+0.36', '+0.01']\n",
      "leg0 ['-0.05', '+1.00', '-0.05', '-1.00', '+0.00']\n",
      "leg1 ['+0.82', '-0.09', '-0.34', '-0.17', '+1.00']\n",
      "\n",
      "action ['-0.02', '+0.03', '-0.03', '+0.18']\n",
      "step 420 total_reward +57.93\n",
      "hull ['-0.09', '+0.03', '+0.39', '-0.00']\n",
      "leg0 ['+1.06', '-0.04', '-0.62', '+0.14', '+0.00']\n",
      "leg1 ['+0.15', '-0.80', '+0.01', '+0.32', '+1.00']\n",
      "\n",
      "action ['-0.01', '+0.31', '+0.10', '-0.04']\n",
      "step 440 total_reward +62.78\n",
      "hull ['-0.01', '-0.01', '+0.42', '+0.00']\n",
      "leg0 ['+0.24', '-0.56', '-0.08', '+0.30', '+1.00']\n",
      "leg1 ['+0.64', '+1.00', '-0.62', '+0.00', '+0.00']\n",
      "\n",
      "action ['+0.13', '-0.29', '-0.03', '+0.46']\n",
      "step 460 total_reward +67.18\n",
      "hull ['-0.04', '-0.02', '+0.39', '+0.04']\n",
      "leg0 ['+0.56', '+1.00', '-0.60', '+0.00', '+0.00']\n",
      "leg1 ['+0.43', '-0.45', '-0.27', '+0.21', '+1.00']\n",
      "\n",
      "action ['+0.01', '+0.79', '+0.32', '-0.28']\n",
      "step 480 total_reward +71.94\n",
      "hull ['+0.03', '-0.01', '+0.40', '+0.02']\n",
      "leg0 ['+0.51', '-0.51', '-0.34', '+0.14', '+1.00']\n",
      "leg1 ['+0.21', '+1.00', '-0.56', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.38', '-0.68', '+0.01', '+1.00']\n",
      "step 500 total_reward +76.81\n",
      "hull ['+0.04', '-0.02', '+0.38', '+0.01']\n",
      "leg0 ['+0.07', '+1.00', '-0.30', '-1.00', '+0.00']\n",
      "leg1 ['+0.67', '-0.28', '-0.44', '-0.06', '+1.00']\n",
      "\n",
      "action ['+0.03', '+0.68', '+0.61', '-1.00']\n",
      "step 520 total_reward +81.54\n",
      "hull ['+0.04', '-0.01', '+0.40', '-0.03']\n",
      "leg0 ['+0.83', '-0.22', '-0.42', '-0.24', '+1.00']\n",
      "leg1 ['-0.19', '+0.81', '+0.03', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.01', '-0.11', '-0.38', '+1.00']\n",
      "step 540 total_reward +86.68\n",
      "hull ['+0.00', '+0.04', '+0.47', '-0.02']\n",
      "leg0 ['-0.12', '-0.94', '+0.16', '+0.07', '+1.00']\n",
      "leg1 ['+1.01', '-0.74', '-0.36', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.03', '-0.38', '-0.03', '+0.44']\n",
      "step 560 total_reward +89.99\n",
      "hull ['-0.05', '-0.01', '+0.32', '+0.05']\n",
      "leg0 ['+0.88', '+0.91', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.52', '-0.40', '-0.31', '+0.20', '+1.00']\n",
      "\n",
      "action ['+0.04', '+0.79', '+0.50', '-0.95']\n",
      "step 580 total_reward +93.80\n",
      "hull ['+0.10', '-0.02', '+0.34', '+0.01']\n",
      "leg0 ['+0.64', '-0.19', '-0.30', '-0.06', '+0.00']\n",
      "leg1 ['-0.13', '+1.00', '-0.18', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.01', '-0.01', '-0.37', '+1.00']\n",
      "step 600 total_reward +98.67\n",
      "hull ['-0.00', '+0.04', '+0.42', '-0.03']\n",
      "leg0 ['-0.08', '-0.99', '+0.22', '+0.46', '+0.00']\n",
      "leg1 ['+0.99', '-0.85', '-0.27', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.00', '-0.24', '-0.07', '+0.46']\n",
      "step 620 total_reward +101.26\n",
      "hull ['-0.11', '-0.03', '+0.26', '+0.04']\n",
      "leg0 ['+0.76', '+0.97', '-0.62', '+0.00', '+0.00']\n",
      "leg1 ['+0.69', '-0.18', '-0.27', '+0.09', '+1.00']\n",
      "\n",
      "action ['-0.08', '+0.57', '+0.05', '+0.14']\n",
      "step 640 total_reward +105.30\n",
      "hull ['+0.07', '+0.04', '+0.36', '-0.06']\n",
      "leg0 ['+0.60', '-1.00', '-0.03', '-0.01', '+1.00']\n",
      "leg1 ['-0.27', '-0.89', '+0.24', '+0.32', '+1.00']\n",
      "\n",
      "action ['-0.02', '+0.26', '-0.05', '-0.04']\n",
      "step 660 total_reward +109.50\n",
      "hull ['-0.03', '-0.00', '+0.39', '-0.03']\n",
      "leg0 ['+0.11', '-0.58', '+0.08', '+0.28', '+1.00']\n",
      "leg1 ['+1.00', '+0.66', '-0.48', '+0.11', '+0.00']\n",
      "\n",
      "action ['+0.36', '-0.34', '-0.01', '+0.76']\n",
      "step 680 total_reward +113.12\n",
      "hull ['+0.00', '-0.03', '+0.22', '+0.01']\n",
      "leg0 ['+0.06', '+1.00', '-0.48', '-1.00', '+0.00']\n",
      "leg1 ['+0.79', '+0.04', '-0.28', '-0.09', '+1.00']\n",
      "\n",
      "action ['-0.00', '-0.15', '-0.05', '+0.33']\n",
      "step 700 total_reward +114.57\n",
      "hull ['-0.12', '+0.02', '+0.21', '+0.02']\n",
      "leg0 ['+1.02', '-0.14', '-0.60', '+0.00', '+0.00']\n",
      "leg1 ['+0.52', '-0.44', '-0.14', '+0.09', '+1.00']\n",
      "\n",
      "action ['+0.08', '+0.36', '+0.71', '-1.00']\n",
      "step 720 total_reward +117.32\n",
      "hull ['+0.15', '-0.01', '+0.31', '+0.04']\n",
      "leg0 ['+0.59', '-0.34', '-0.40', '+1.00', '+0.00']\n",
      "leg1 ['-0.32', '+0.89', '+0.20', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.02', '+0.19', '-0.06', '-0.02']\n",
      "step 740 total_reward +121.77\n",
      "hull ['-0.03', '+0.00', '+0.38', '-0.03']\n",
      "leg0 ['+0.06', '-0.64', '+0.10', '+0.33', '+1.00']\n",
      "leg1 ['+1.09', '+0.37', '-0.50', '+0.17', '+0.00']\n",
      "\n",
      "action ['-0.06', '-0.38', '-0.07', '+0.47']\n",
      "step 760 total_reward +123.89\n",
      "hull ['-0.12', '-0.02', '+0.22', '+0.05']\n",
      "leg0 ['+0.91', '+0.80', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.77', '-0.24', '-0.33', '+0.13', '+1.00']\n",
      "\n",
      "action ['-0.25', '+1.00', '+0.04', '+0.16']\n",
      "step 780 total_reward +127.30\n",
      "hull ['+0.05', '+0.04', '+0.30', '-0.02']\n",
      "leg0 ['+0.85', '-0.98', '-0.30', '+1.00', '+0.00']\n",
      "leg1 ['-0.05', '-0.78', '+0.08', '+0.26', '+1.00']\n",
      "\n",
      "action ['-0.02', '+0.37', '+0.10', '-0.02']\n",
      "step 800 total_reward +131.03\n",
      "hull ['-0.01', '-0.03', '+0.34', '-0.00']\n",
      "leg0 ['+0.32', '-0.26', '-0.07', '+0.14', '+1.00']\n",
      "leg1 ['+0.65', '+1.00', '-0.58', '+0.09', '+0.00']\n",
      "\n",
      "action ['+0.26', '-0.49', '-0.03', '+0.76']\n",
      "step 820 total_reward +134.60\n",
      "hull ['-0.04', '-0.02', '+0.27', '+0.03']\n",
      "leg0 ['+0.26', '+1.00', '-0.49', '-1.00', '+0.00']\n",
      "leg1 ['+0.80', '-0.16', '-0.36', '-0.02', '+1.00']\n",
      "\n",
      "action ['+0.03', '+0.04', '-0.00', '+0.25']\n",
      "step 840 total_reward +137.99\n",
      "hull ['-0.04', '+0.03', '+0.32', '-0.01']\n",
      "leg0 ['+1.04', '-0.13', '-0.59', '+0.16', '+0.00']\n",
      "leg1 ['+0.14', '-0.67', '-0.00', '+0.22', '+1.00']\n",
      "\n",
      "action ['+0.00', '+0.37', '+0.17', '-0.05']\n",
      "step 860 total_reward +141.75\n",
      "hull ['+0.03', '-0.02', '+0.36', '+0.01']\n",
      "leg0 ['+0.32', '-0.36', '-0.13', '+0.18', '+1.00']\n",
      "leg1 ['+0.53', '+1.00', '-0.62', '-0.00', '+0.00']\n",
      "\n",
      "action ['+0.44', '-0.85', '+0.01', '+0.81']\n",
      "step 880 total_reward +145.82\n",
      "hull ['+0.05', '-0.02', '+0.27', '-0.01']\n",
      "leg0 ['-0.04', '+1.00', '-0.17', '-1.00', '+0.00']\n",
      "leg1 ['+0.76', '+0.01', '-0.25', '-0.20', '+1.00']\n",
      "\n",
      "action ['-0.01', '-0.13', '-0.02', '+0.32']\n",
      "step 900 total_reward +148.25\n",
      "hull ['-0.07', '+0.02', '+0.25', '+0.02']\n",
      "leg0 ['+1.09', '-0.11', '-0.63', '+0.00', '+0.00']\n",
      "leg1 ['+0.44', '-0.50', '-0.15', '+0.13', '+1.00']\n",
      "\n",
      "action ['+0.06', '+0.10', '+0.62', '-1.00']\n",
      "step 920 total_reward +151.02\n",
      "hull ['+0.16', '-0.03', '+0.32', '-0.01']\n",
      "leg0 ['+0.50', '-0.01', '-0.08', '-0.15', '+1.00']\n",
      "leg1 ['-0.35', '+1.00', '+0.14', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.04', '+0.23', '-0.06', '-0.02']\n",
      "step 940 total_reward +155.35\n",
      "hull ['-0.07', '+0.00', '+0.38', '-0.03']\n",
      "leg0 ['+0.16', '-0.59', '+0.08', '+0.27', '+1.00']\n",
      "leg1 ['+1.06', '+0.33', '-0.50', '+0.10', '+0.00']\n",
      "\n",
      "action ['+0.23', '-0.03', '-0.05', '+0.65']\n",
      "step 960 total_reward +158.84\n",
      "hull ['-0.07', '-0.02', '+0.25', '+0.01']\n",
      "leg0 ['+0.29', '+1.00', '-0.65', '-0.96', '+0.00']\n",
      "leg1 ['+0.78', '-0.04', '-0.24', '-0.07', '+0.00']\n",
      "\n",
      "action ['+0.05', '+0.02', '-0.02', '+0.29']\n",
      "step 980 total_reward +161.90\n",
      "hull ['-0.08', '+0.03', '+0.29', '-0.01']\n",
      "leg0 ['+0.98', '-0.14', '-0.60', '+0.06', '+0.00']\n",
      "leg1 ['+0.25', '-0.61', '-0.03', '+0.16', '+0.00']\n",
      "\n",
      "action ['+0.02', '+0.46', '+0.30', '+0.20']\n",
      "step 1000 total_reward +165.58\n",
      "hull ['+0.06', '-0.02', '+0.35', '+0.01']\n",
      "leg0 ['+0.33', '-0.30', '-0.11', '+0.12', '+1.00']\n",
      "leg1 ['+0.28', '+1.00', '-0.63', '-0.00', '+0.00']\n",
      "\n",
      "action ['+0.23', '-0.38', '-0.03', '+0.78']\n",
      "step 1020 total_reward +170.06\n",
      "hull ['-0.05', '-0.02', '+0.38', '+0.03']\n",
      "leg0 ['+0.31', '+1.00', '-0.55', '-1.00', '+0.00']\n",
      "leg1 ['+0.64', '-0.32', '-0.37', '+0.06', '+1.00']\n",
      "\n",
      "action ['-0.01', '+0.85', '+0.50', '-1.00']\n",
      "step 1040 total_reward +175.20\n",
      "hull ['-0.02', '-0.01', '+0.41', '-0.03']\n",
      "leg0 ['+0.74', '-0.26', '-0.39', '-0.13', '+1.00']\n",
      "leg1 ['-0.16', '+1.00', '+0.02', '-1.00', '+0.00']\n",
      "\n",
      "action ['+0.06', '+1.00', '-0.07', '+0.62']\n",
      "step 1060 total_reward +180.34\n",
      "hull ['+0.08', '+0.05', '+0.49', '-0.07']\n",
      "leg0 ['-0.51', '-1.30', '+0.49', '+1.00', '+0.00']\n",
      "leg1 ['+0.69', '-0.32', '-0.18', '-0.66', '+0.00']\n",
      "\n",
      "action ['-0.49', '+1.00', '-0.01', '+0.22']\n",
      "step 1080 total_reward +185.21\n",
      "hull ['+0.00', '+0.02', '+0.45', '-0.00']\n",
      "leg0 ['+0.93', '+0.05', '-0.46', '+1.00', '+0.00']\n",
      "leg1 ['-0.01', '-0.87', '+0.05', '+0.44', '+0.00']\n",
      "\n",
      "action ['-0.03', '+0.30', '+0.00', '-0.07']\n",
      "step 1100 total_reward +189.60\n",
      "hull ['-0.05', '-0.01', '+0.42', '+0.01']\n",
      "leg0 ['+0.29', '-0.55', '-0.08', '+0.30', '+1.00']\n",
      "leg1 ['+0.82', '+0.96', '-0.61', '-0.00', '+0.00']\n",
      "\n",
      "action ['+0.19', '+0.07', '-0.02', '+0.63']\n",
      "step 1120 total_reward +193.99\n",
      "hull ['-0.03', '-0.02', '+0.33', '+0.05']\n",
      "leg0 ['+0.43', '+0.94', '-0.63', '+0.00', '+0.00']\n",
      "leg1 ['+0.62', '-0.34', '-0.33', '+0.11', '+1.00']\n",
      "\n",
      "action ['+0.10', '+0.23', '+0.99', '-1.00']\n",
      "step 1140 total_reward +197.95\n",
      "hull ['+0.13', '+0.02', '+0.39', '-0.01']\n",
      "leg0 ['+0.68', '-0.34', '-0.23', '-0.24', '+1.00']\n",
      "leg1 ['-0.45', '+0.22', '+0.31', '-1.00', '+1.00']\n",
      "\n",
      "action ['-0.02', '+0.22', '-0.05', '-0.03']\n",
      "step 1160 total_reward +202.60\n",
      "hull ['-0.03', '-0.00', '+0.40', '-0.02']\n",
      "leg0 ['+0.12', '-0.63', '+0.06', '+0.32', '+1.00']\n",
      "leg1 ['+1.03', '+0.58', '-0.53', '+0.16', '+0.00']\n",
      "\n",
      "action ['+0.35', '-0.29', '-0.02', '+0.73']\n",
      "step 1180 total_reward +206.27\n",
      "hull ['-0.01', '-0.03', '+0.23', '+0.00']\n",
      "leg0 ['+0.08', '+1.00', '-0.50', '-1.00', '+0.00']\n",
      "leg1 ['+0.77', '+0.05', '-0.26', '-0.11', '+1.00']\n",
      "\n",
      "action ['+0.01', '-0.08', '-0.04', '+0.32']\n",
      "step 1200 total_reward +208.05\n",
      "hull ['-0.12', '+0.02', '+0.23', '+0.01']\n",
      "leg0 ['+1.00', '-0.13', '-0.62', '+0.00', '+0.00']\n",
      "leg1 ['+0.47', '-0.48', '-0.12', '+0.10', '+1.00']\n",
      "\n",
      "action ['+0.08', '+0.30', '+0.77', '-1.00']\n",
      "step 1220 total_reward +211.05\n",
      "hull ['+0.16', '-0.02', '+0.32', '+0.00']\n",
      "leg0 ['+0.42', '-0.15', '-0.07', '-0.03', '+1.00']\n",
      "leg1 ['-0.45', '+0.97', '+0.27', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.02', '+0.05', '-0.37', '+0.96']\n",
      "step 1240 total_reward +215.72\n",
      "hull ['-0.04', '+0.02', '+0.42', '-0.05']\n",
      "leg0 ['-0.07', '-0.90', '+0.24', '+0.45', '+1.00']\n",
      "leg1 ['+0.88', '-0.51', '-0.19', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.00', '-0.14', '-0.04', '+0.46']\n",
      "step 1260 total_reward +218.83\n",
      "hull ['-0.07', '-0.01', '+0.29', '+0.02']\n",
      "leg0 ['+0.81', '+0.96', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.49', '-0.30', '-0.20', '+0.11', '+1.00']\n",
      "\n",
      "action ['+0.04', '+0.56', '+0.54', '-1.00']\n",
      "step 1280 total_reward +222.60\n",
      "hull ['+0.11', '-0.02', '+0.33', '-0.01']\n",
      "leg0 ['+0.62', '-0.06', '-0.15', '-0.18', '+1.00']\n",
      "leg1 ['-0.21', '+1.00', '-0.07', '-1.00', '+0.00']\n",
      "\n",
      "action ['-0.02', '+0.21', '-0.05', '-0.01']\n",
      "step 1300 total_reward +227.03\n",
      "hull ['-0.05', '+0.01', '+0.38', '-0.02']\n",
      "leg0 ['+0.14', '-0.67', '+0.08', '+0.29', '+1.00']\n",
      "leg1 ['+1.11', '+0.19', '-0.52', '+0.15', '+0.00']\n",
      "\n",
      "action ['+0.12', '-0.20', '-0.05', '+0.50']\n",
      "step 1320 total_reward +230.27\n",
      "hull ['-0.07', '-0.03', '+0.26', '+0.03']\n",
      "leg0 ['+0.53', '+1.00', '-0.63', '+0.00', '+0.00']\n",
      "leg1 ['+0.71', '-0.12', '-0.28', '+0.05', '+1.00']\n",
      "\n",
      "action ['-0.25', '+1.00', '+0.02', '+0.10']\n",
      "step 1340 total_reward +234.25\n",
      "hull ['+0.00', '+0.05', '+0.35', '-0.03']\n",
      "leg0 ['+0.85', '-1.00', '-0.38', '-0.19', '+1.00']\n",
      "leg1 ['-0.06', '-0.89', '+0.13', '+0.31', '+1.00']\n",
      "\n",
      "action ['-0.01', '+0.19', '-0.49', '+1.00']\n",
      "step 1360 total_reward +238.61\n",
      "hull ['+0.00', '+0.01', '+0.44', '+0.00']\n",
      "leg0 ['+0.02', '-0.90', '+0.05', '+0.53', '+1.00']\n",
      "leg1 ['+0.94', '+0.03', '-0.48', '+1.00', '+0.00']\n",
      "\n",
      "action ['-0.06', '-0.28', '-0.05', '+0.19']\n",
      "step 1380 total_reward +243.28\n",
      "hull ['-0.11', '+0.01', '+0.51', '+0.03']\n",
      "leg0 ['+0.99', '+0.48', '-0.61', '+0.00', '+0.00']\n",
      "leg1 ['+0.12', '-0.96', '-0.10', '+0.58', '+1.00']\n",
      "\n",
      "action ['-0.03', '+1.00', '-0.27', '+0.21']\n",
      "step 1400 total_reward +249.76\n",
      "hull ['-0.09', '+0.03', '+0.61', '-0.03']\n",
      "leg0 ['-0.21', '-1.38', '+0.29', '+1.00', '+0.00']\n",
      "leg1 ['+0.62', '-0.65', '-0.42', '-0.03', '+1.00']\n",
      "\n",
      "action ['+0.10', '+0.12', '-0.16', '+1.00']\n",
      "step 1420 total_reward +256.67\n",
      "hull ['-0.30', '-0.04', '+0.72', '-0.14']\n",
      "leg0 ['-0.28', '-0.95', '+0.54', '+1.00', '+1.00']\n",
      "leg1 ['-0.38', '-1.00', '+0.53', '+1.00', '+1.00']\n",
      "\n",
      "action ['+0.07', '+0.89', '-0.35', '+0.89']\n",
      "step 1433 total_reward +160.16\n",
      "hull ['-0.62', '+0.05', '+0.46', '-0.08']\n",
      "leg0 ['-0.82', '-0.00', '+0.93', '+0.00', '+0.00']\n",
      "leg1 ['-0.83', '-1.00', '+0.93', '+0.00', '+0.00']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import pygame\n",
    "\n",
    "FPS = 50\n",
    "SCALE = 30.0  # affects how fast-paced the game is, forces should be adjusted as well\n",
    "\n",
    "MOTORS_TORQUE = 80\n",
    "SPEED_HIP = 4\n",
    "SPEED_KNEE = 6\n",
    "LIDAR_RANGE = 160 / SCALE\n",
    "\n",
    "INITIAL_RANDOM = 5\n",
    "\n",
    "HULL_POLY = [(-30, +9), (+6, +9), (+34, +1), (+34, -8), (-30, -8)]\n",
    "\n",
    "LEG_DOWN = -8 / SCALE\n",
    "LEG_W, LEG_H = 8 / SCALE, 34 / SCALE\n",
    "\n",
    "VIEWPORT_W = 600\n",
    "VIEWPORT_H = 400\n",
    "\n",
    "TERRAIN_STEP = 14 / SCALE\n",
    "TERRAIN_LENGTH = 200  # in steps\n",
    "TERRAIN_HEIGHT = VIEWPORT_H / SCALE / 4\n",
    "TERRAIN_GRASS = 10  # low long are grass spots, in steps\n",
    "TERRAIN_STARTPAD = 20  # in steps\n",
    "FRICTION = 2.5\n",
    "\n",
    "HULL_FD = fixtureDef(\n",
    "    shape=polygonShape(vertices=[(x / SCALE, y / SCALE) for x, y in HULL_POLY]),\n",
    "    density=5.0,\n",
    "    friction=0.1,\n",
    "    categoryBits=0x0020,\n",
    "    maskBits=0x001,  # collide only with ground\n",
    "    restitution=0.0,\n",
    ")  # 0.99 bouncy\n",
    "\n",
    "LEG_FD = fixtureDef(\n",
    "    shape=polygonShape(box=(LEG_W / 2, LEG_H / 2)),\n",
    "    density=1.0,\n",
    "    restitution=0.0,\n",
    "    categoryBits=0x0020,\n",
    "    maskBits=0x001,\n",
    ")\n",
    "\n",
    "LOWER_FD = fixtureDef(\n",
    "    shape=polygonShape(box=(0.8 * LEG_W / 2, LEG_H / 2)),  \n",
    "\n",
    "    density=1.0,\n",
    "    restitution=0.0,\n",
    "    categoryBits=0x0020,\n",
    "    maskBits=0x001,\n",
    ")\n",
    "\n",
    "\n",
    "class ContactDetector(contactListener):\n",
    "    def __init__(self, env):\n",
    "        contactListener.__init__(self)\n",
    "        self.env = env\n",
    "\n",
    "    def BeginContact(self, contact):\n",
    "        if (\n",
    "            self.env.hull == contact.fixtureA.body\n",
    "            or self.env.hull == contact.fixtureB.body\n",
    "        ):\n",
    "            self.env.game_over = True\n",
    "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
    "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
    "                leg.ground_contact = True\n",
    "\n",
    "    def EndContact(self, contact):\n",
    "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
    "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
    "                leg.ground_contact = False\n",
    "\n",
    "\n",
    "class BipedalWalker(gym.Env, EzPickle):\n",
    "    \"\"\"\n",
    "    ## Description\n",
    "    This is a simple 4-joint walker robot environment.\n",
    "    There are two versions:\n",
    "    - Normal, with slightly uneven terrain.\n",
    "    - Hardcore, with ladders, stumps, pitfalls.\n",
    "\n",
    "    To solve the normal version, you need to get 300 points in 1600 time steps.\n",
    "    To solve the hardcore version, you need 300 points in 2000 time steps.\n",
    "\n",
    "    A heuristic is provided for testing. It's also useful to get demonstrations\n",
    "    to learn from. To run the heuristic:\n",
    "    ```\n",
    "    python gymnasium/envs/box2d/bipedal_walker.py\n",
    "    ```\n",
    "\n",
    "    ## Action Space\n",
    "    Actions are motor speed values in the [-1, 1] range for each of the\n",
    "    4 joints at both hips and knees.\n",
    "\n",
    "    ## Observation Space\n",
    "    State consists of hull angle speed, angular velocity, horizontal speed,\n",
    "    vertical speed, position of joints and joints angular speed, legs contact\n",
    "    with ground, and 10 lidar rangefinder measurements. There are no coordinates\n",
    "    in the state vector.\n",
    "\n",
    "    ## Rewards\n",
    "    Reward is given for moving forward, totaling 300+ points up to the far end.\n",
    "    If the robot falls, it gets -100. Applying motor torque costs a small\n",
    "    amount of points. A more optimal agent will get a better score.\n",
    "\n",
    "    ## Starting State\n",
    "    The walker starts standing at the left end of the terrain with the hull\n",
    "    horizontal, and both legs in the same position with a slight knee angle.\n",
    "\n",
    "    ## Episode Termination\n",
    "    The episode will terminate if the hull gets in contact with the ground or\n",
    "    if the walker exceeds the right end of the terrain length.\n",
    "\n",
    "    ## Arguments\n",
    "    To use the _hardcore_ environment, you need to specify the\n",
    "    `hardcore=True` argument like below:\n",
    "    ```python\n",
    "    import gymnasium as gym\n",
    "    env = gym.make(\"BipedalWalker-v3\", hardcore=True)\n",
    "    ```\n",
    "\n",
    "    ## Version History\n",
    "    - v3: Returns the closest lidar trace instead of furthest;\n",
    "        faster video recording\n",
    "    - v2: Count energy spent\n",
    "    - v1: Legs now report contact with ground; motors have higher torque and\n",
    "        speed; ground has higher friction; lidar rendered less nervously.\n",
    "    - v0: Initial version\n",
    "\n",
    "\n",
    "    <!-- ## References -->\n",
    "\n",
    "    ## Credits\n",
    "    Created by Oleg Klimov\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": FPS,\n",
    "    }\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, hardcore: bool = False):\n",
    "        EzPickle.__init__(self, render_mode, hardcore)\n",
    "        self.isopen = True\n",
    "\n",
    "        self.world = Box2D.b2World()\n",
    "        self.terrain: List[Box2D.b2Body] = []\n",
    "        self.hull: Optional[Box2D.b2Body] = None\n",
    "\n",
    "        self.prev_shaping = None\n",
    "\n",
    "        self.hardcore = hardcore\n",
    "\n",
    "        self.fd_polygon = fixtureDef(\n",
    "            shape=polygonShape(vertices=[(0, 0), (1, 0), (1, -1), (0, -1)]),\n",
    "            friction=FRICTION,\n",
    "        )\n",
    "\n",
    "        self.fd_edge = fixtureDef(\n",
    "            shape=edgeShape(vertices=[(0, 0), (1, 1)]),\n",
    "            friction=FRICTION,\n",
    "            categoryBits=0x0001,\n",
    "        )\n",
    "\n",
    "        # we use 5.0 to represent the joints moving at maximum\n",
    "        # 5 x the rated speed due to impulses from ground contact etc.\n",
    "        low = np.array(\n",
    "            [\n",
    "                -math.pi,\n",
    "                -5.0,\n",
    "                -5.0,\n",
    "                -5.0,\n",
    "                -math.pi,\n",
    "                -5.0,\n",
    "                -math.pi,\n",
    "                -5.0,\n",
    "                -0.0,\n",
    "                -math.pi,\n",
    "                -5.0,\n",
    "                -math.pi,\n",
    "                -5.0,\n",
    "                -0.0,\n",
    "            ]\n",
    "            + [-1.0] * 10\n",
    "        ).astype(np.float32)\n",
    "        high = np.array(\n",
    "            [\n",
    "                math.pi,\n",
    "                5.0,\n",
    "                5.0,\n",
    "                5.0,\n",
    "                math.pi,\n",
    "                5.0,\n",
    "                math.pi,\n",
    "                5.0,\n",
    "                5.0,\n",
    "                math.pi,\n",
    "                5.0,\n",
    "                math.pi,\n",
    "                5.0,\n",
    "                5.0,\n",
    "            ]\n",
    "            + [1.0] * 10\n",
    "        ).astype(np.float32)\n",
    "        self.action_space = spaces.Box(\n",
    "            np.array([-1, -1, -1, -1]).astype(np.float32),\n",
    "            np.array([1, 1, 1, 1]).astype(np.float32),\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low, high)\n",
    "\n",
    "        # state = [\n",
    "        #     self.hull.angle,  # Normal angles up to 0.5 here, but sure more is possible.\n",
    "        #     2.0 * self.hull.angularVelocity / FPS,\n",
    "        #     0.3 * vel.x * (VIEWPORT_W / SCALE) / FPS,  # Normalized to get -1..1 range\n",
    "        #     0.3 * vel.y * (VIEWPORT_H / SCALE) / FPS,\n",
    "        #     self.joints[\n",
    "        #         0\n",
    "        #     ].angle,  # This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)\n",
    "        #     self.joints[0].speed / SPEED_HIP,\n",
    "        #     self.joints[1].angle + 1.0,\n",
    "        #     self.joints[1].speed / SPEED_KNEE,\n",
    "        #     1.0 if self.legs[1].ground_contact else 0.0,\n",
    "        #     self.joints[2].angle,\n",
    "        #     self.joints[2].speed / SPEED_HIP,\n",
    "        #     self.joints[3].angle + 1.0,\n",
    "        #     self.joints[3].speed / SPEED_KNEE,\n",
    "        #     1.0 if self.legs[3].ground_contact else 0.0,\n",
    "        # ]\n",
    "        # state += [l.fraction for l in self.lidar]\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "        self.screen: Optional[pygame.Surface] = None\n",
    "        self.clock = None\n",
    "\n",
    "    def _destroy(self):\n",
    "        if not self.terrain:\n",
    "            return\n",
    "        self.world.contactListener = None\n",
    "        for t in self.terrain:\n",
    "            self.world.DestroyBody(t)\n",
    "        self.terrain = []\n",
    "        self.world.DestroyBody(self.hull)\n",
    "        self.hull = None\n",
    "        for leg in self.legs:\n",
    "            self.world.DestroyBody(leg)\n",
    "        self.legs = []\n",
    "        self.joints = []\n",
    "\n",
    "    def _generate_terrain(self, hardcore):\n",
    "        GRASS, STUMP, STAIRS, PIT, _STATES_ = range(5)\n",
    "        state = GRASS\n",
    "        velocity = 0.0\n",
    "        y = TERRAIN_HEIGHT\n",
    "        counter = TERRAIN_STARTPAD\n",
    "        oneshot = False\n",
    "        self.terrain = []\n",
    "        self.terrain_x = []\n",
    "        self.terrain_y = []\n",
    "\n",
    "        stair_steps, stair_width, stair_height = 0, 0, 0\n",
    "        original_y = 0\n",
    "        for i in range(TERRAIN_LENGTH):\n",
    "            x = i * TERRAIN_STEP\n",
    "            self.terrain_x.append(x)\n",
    "\n",
    "            if state == GRASS and not oneshot:\n",
    "                velocity = 0.8 * velocity + 0.01 * np.sign(TERRAIN_HEIGHT - y)\n",
    "                if i > TERRAIN_STARTPAD:\n",
    "                    velocity += self.np_random.uniform(-1, 1) / SCALE  # 1\n",
    "                y += velocity\n",
    "\n",
    "            elif state == PIT and oneshot:\n",
    "                counter = self.np_random.integers(3, 5)\n",
    "                poly = [\n",
    "                    (x, y),\n",
    "                    (x + TERRAIN_STEP, y),\n",
    "                    (x + TERRAIN_STEP, y - 4 * TERRAIN_STEP),\n",
    "                    (x, y - 4 * TERRAIN_STEP),\n",
    "                ]\n",
    "                self.fd_polygon.shape.vertices = poly\n",
    "                t = self.world.CreateStaticBody(fixtures=self.fd_polygon)\n",
    "                t.color1, t.color2 = (255, 255, 255), (153, 153, 153)\n",
    "                self.terrain.append(t)\n",
    "\n",
    "                self.fd_polygon.shape.vertices = [\n",
    "                    (p[0] + TERRAIN_STEP * counter, p[1]) for p in poly\n",
    "                ]\n",
    "                t = self.world.CreateStaticBody(fixtures=self.fd_polygon)\n",
    "                t.color1, t.color2 = (255, 255, 255), (153, 153, 153)\n",
    "                self.terrain.append(t)\n",
    "                counter += 2\n",
    "                original_y = y\n",
    "\n",
    "            elif state == PIT and not oneshot:\n",
    "                y = original_y\n",
    "                if counter > 1:\n",
    "                    y -= 4 * TERRAIN_STEP\n",
    "\n",
    "            elif state == STUMP and oneshot:\n",
    "                counter = self.np_random.integers(1, 3)\n",
    "                poly = [\n",
    "                    (x, y),\n",
    "                    (x + counter * TERRAIN_STEP, y),\n",
    "                    (x + counter * TERRAIN_STEP, y + counter * TERRAIN_STEP),\n",
    "                    (x, y + counter * TERRAIN_STEP),\n",
    "                ]\n",
    "                self.fd_polygon.shape.vertices = poly\n",
    "                t = self.world.CreateStaticBody(fixtures=self.fd_polygon)\n",
    "                t.color1, t.color2 = (255, 255, 255), (153, 153, 153)\n",
    "                self.terrain.append(t)\n",
    "\n",
    "            elif state == STAIRS and oneshot:\n",
    "                stair_height = +1 if self.np_random.random() > 0.5 else -1\n",
    "                stair_width = self.np_random.integers(4, 5)\n",
    "                stair_steps = self.np_random.integers(3, 5)\n",
    "                original_y = y\n",
    "                for s in range(stair_steps):\n",
    "                    poly = [\n",
    "                        (\n",
    "                            x + (s * stair_width) * TERRAIN_STEP,\n",
    "                            y + (s * stair_height) * TERRAIN_STEP,\n",
    "                        ),\n",
    "                        (\n",
    "                            x + ((1 + s) * stair_width) * TERRAIN_STEP,\n",
    "                            y + (s * stair_height) * TERRAIN_STEP,\n",
    "                        ),\n",
    "                        (\n",
    "                            x + ((1 + s) * stair_width) * TERRAIN_STEP,\n",
    "                            y + (-1 + s * stair_height) * TERRAIN_STEP,\n",
    "                        ),\n",
    "                        (\n",
    "                            x + (s * stair_width) * TERRAIN_STEP,\n",
    "                            y + (-1 + s * stair_height) * TERRAIN_STEP,\n",
    "                        ),\n",
    "                    ]\n",
    "                    self.fd_polygon.shape.vertices = poly\n",
    "                    t = self.world.CreateStaticBody(fixtures=self.fd_polygon)\n",
    "                    t.color1, t.color2 = (255, 255, 255), (153, 153, 153)\n",
    "                    self.terrain.append(t)\n",
    "                counter = stair_steps * stair_width\n",
    "\n",
    "            elif state == STAIRS and not oneshot:\n",
    "                s = stair_steps * stair_width - counter - stair_height\n",
    "                n = s / stair_width\n",
    "                y = original_y + (n * stair_height) * TERRAIN_STEP\n",
    "\n",
    "            oneshot = False\n",
    "            self.terrain_y.append(y)\n",
    "            counter -= 1\n",
    "            if counter == 0:\n",
    "                counter = self.np_random.integers(TERRAIN_GRASS / 2, TERRAIN_GRASS)\n",
    "                if state == GRASS and hardcore:\n",
    "                    state = self.np_random.integers(1, _STATES_)\n",
    "                    oneshot = True\n",
    "                else:\n",
    "                    state = GRASS\n",
    "                    oneshot = True\n",
    "\n",
    "        self.terrain_poly = []\n",
    "        for i in range(TERRAIN_LENGTH - 1):\n",
    "            poly = [\n",
    "                (self.terrain_x[i], self.terrain_y[i]),\n",
    "                (self.terrain_x[i + 1], self.terrain_y[i + 1]),\n",
    "            ]\n",
    "            self.fd_edge.shape.vertices = poly\n",
    "            t = self.world.CreateStaticBody(fixtures=self.fd_edge)\n",
    "            color = (76, 255 if i % 2 == 0 else 204, 76)\n",
    "            t.color1 = color\n",
    "            t.color2 = color\n",
    "            self.terrain.append(t)\n",
    "            color = (102, 153, 76)\n",
    "            poly += [(poly[1][0], 0), (poly[0][0], 0)]\n",
    "            self.terrain_poly.append((poly, color))\n",
    "        self.terrain.reverse()\n",
    "\n",
    "    def _generate_clouds(self):\n",
    "        # Sorry for the clouds, couldn't resist\n",
    "        self.cloud_poly = []\n",
    "        for i in range(TERRAIN_LENGTH // 20):\n",
    "            x = self.np_random.uniform(0, TERRAIN_LENGTH) * TERRAIN_STEP\n",
    "            y = VIEWPORT_H / SCALE * 3 / 4\n",
    "            poly = [\n",
    "                (\n",
    "                    x\n",
    "                    + 15 * TERRAIN_STEP * math.sin(3.14 * 2 * a / 5)\n",
    "                    + self.np_random.uniform(0, 5 * TERRAIN_STEP),\n",
    "                    y\n",
    "                    + 5 * TERRAIN_STEP * math.cos(3.14 * 2 * a / 5)\n",
    "                    + self.np_random.uniform(0, 5 * TERRAIN_STEP),\n",
    "                )\n",
    "                for a in range(5)\n",
    "            ]\n",
    "            x1 = min(p[0] for p in poly)\n",
    "            x2 = max(p[0] for p in poly)\n",
    "            self.cloud_poly.append((poly, x1, x2))\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        self._destroy()\n",
    "        self.world.contactListener_bug_workaround = ContactDetector(self)\n",
    "        self.world.contactListener = self.world.contactListener_bug_workaround\n",
    "        self.game_over = False\n",
    "        self.prev_shaping = None\n",
    "        self.scroll = 0.0\n",
    "        self.lidar_render = 0\n",
    "\n",
    "        self._generate_terrain(self.hardcore)\n",
    "        self._generate_clouds()\n",
    "\n",
    "        init_x = TERRAIN_STEP * TERRAIN_STARTPAD / 2\n",
    "        init_y = TERRAIN_HEIGHT + 2 * LEG_H\n",
    "        self.hull = self.world.CreateDynamicBody(\n",
    "            position=(init_x, init_y), fixtures=HULL_FD\n",
    "        )\n",
    "        self.hull.color1 = (127, 51, 229)\n",
    "        self.hull.color2 = (76, 76, 127)\n",
    "        self.hull.ApplyForceToCenter(\n",
    "            (self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM), 0), True\n",
    "        )\n",
    "\n",
    "        self.legs: List[Box2D.b2Body] = []  #acrescentar FOOT_FD\n",
    "        self.joints: List[Box2D.b2RevoluteJoint] = []       #acrescentar uma joint do foot\n",
    "        for i in [-1, +1]:\n",
    "            leg = self.world.CreateDynamicBody(\n",
    "                position=(init_x, init_y - LEG_H / 2 - LEG_DOWN),\n",
    "                angle=(i * 0.05),\n",
    "                fixtures=LEG_FD,\n",
    "            )\n",
    "            leg.color1 = (153 - i * 25, 76 - i * 25, 127 - i * 25)\n",
    "            leg.color2 = (102 - i * 25, 51 - i * 25, 76 - i * 25)\n",
    "            rjd = revoluteJointDef(\n",
    "                bodyA=self.hull,\n",
    "                bodyB=leg,\n",
    "                localAnchorA=(0, LEG_DOWN),\n",
    "                localAnchorB=(0, LEG_H / 2),\n",
    "                enableMotor=True,\n",
    "                enableLimit=True,\n",
    "                maxMotorTorque=MOTORS_TORQUE,\n",
    "                motorSpeed=i,\n",
    "                lowerAngle=-0.8,\n",
    "                upperAngle=1.1,\n",
    "            )\n",
    "            self.legs.append(leg)\n",
    "            self.joints.append(self.world.CreateJoint(rjd))\n",
    "\n",
    "            lower = self.world.CreateDynamicBody(\n",
    "                position=(init_x, init_y - LEG_H * 3 / 2 - LEG_DOWN),\n",
    "                angle=(i * 0.05),\n",
    "                fixtures=LOWER_FD,\n",
    "            )\n",
    "            lower.color1 = (153 - i * 25, 76 - i * 25, 127 - i * 25)\n",
    "            lower.color2 = (102 - i * 25, 51 - i * 25, 76 - i * 25)\n",
    "            rjd = revoluteJointDef(\n",
    "                bodyA=leg,\n",
    "                bodyB=lower,\n",
    "                localAnchorA=(0, -LEG_H / 2),\n",
    "                localAnchorB=(0, LEG_H / 2),\n",
    "                enableMotor=True,\n",
    "                enableLimit=True,\n",
    "                maxMotorTorque=MOTORS_TORQUE,\n",
    "                motorSpeed=1,\n",
    "                lowerAngle=-1.6,\n",
    "                upperAngle=-0.1,\n",
    "            )\n",
    "            lower.ground_contact = False\n",
    "            self.legs.append(lower)\n",
    "            self.joints.append(self.world.CreateJoint(rjd))\n",
    "\n",
    "        self.drawlist = self.terrain + self.legs + [self.hull]\n",
    "\n",
    "        class LidarCallback(Box2D.b2.rayCastCallback):\n",
    "            def ReportFixture(self, fixture, point, normal, fraction):\n",
    "                if (fixture.filterData.categoryBits & 1) == 0:\n",
    "                    return -1\n",
    "                self.p2 = point\n",
    "                self.fraction = fraction\n",
    "                return fraction\n",
    "\n",
    "        self.lidar = [LidarCallback() for _ in range(10)]\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return self.step(np.array([0, 0, 0, 0]))[0], {}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        assert self.hull is not None\n",
    "\n",
    "        # self.hull.ApplyForceToCenter((0, 20), True) -- Uncomment this to receive a bit of stability help\n",
    "        control_speed = False  # Should be easier as well\n",
    "        if control_speed:\n",
    "            self.joints[0].motorSpeed = float(SPEED_HIP * np.clip(action[0], -1, 1))\n",
    "            self.joints[1].motorSpeed = float(SPEED_KNEE * np.clip(action[1], -1, 1))\n",
    "            self.joints[2].motorSpeed = float(SPEED_HIP * np.clip(action[2], -1, 1))\n",
    "            self.joints[3].motorSpeed = float(SPEED_KNEE * np.clip(action[3], -1, 1))\n",
    "        else:\n",
    "            self.joints[0].motorSpeed = float(SPEED_HIP * np.sign(action[0]))\n",
    "            self.joints[0].maxMotorTorque = float(\n",
    "                MOTORS_TORQUE * np.clip(np.abs(action[0]), 0, 1)\n",
    "            )\n",
    "            self.joints[1].motorSpeed = float(SPEED_KNEE * np.sign(action[1]))\n",
    "            self.joints[1].maxMotorTorque = float(\n",
    "                MOTORS_TORQUE * np.clip(np.abs(action[1]), 0, 1)\n",
    "            )\n",
    "            self.joints[2].motorSpeed = float(SPEED_HIP * np.sign(action[2]))\n",
    "            self.joints[2].maxMotorTorque = float(\n",
    "                MOTORS_TORQUE * np.clip(np.abs(action[2]), 0, 1)\n",
    "            )\n",
    "            self.joints[3].motorSpeed = float(SPEED_KNEE * np.sign(action[3]))\n",
    "            self.joints[3].maxMotorTorque = float(\n",
    "                MOTORS_TORQUE * np.clip(np.abs(action[3]), 0, 1)\n",
    "            )\n",
    "\n",
    "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
    "\n",
    "        pos = self.hull.position\n",
    "        vel = self.hull.linearVelocity\n",
    "\n",
    "        for i in range(10):\n",
    "            self.lidar[i].fraction = 1.0\n",
    "            self.lidar[i].p1 = pos\n",
    "            self.lidar[i].p2 = (\n",
    "                pos[0] + math.sin(1.5 * i / 10.0) * LIDAR_RANGE,\n",
    "                pos[1] - math.cos(1.5 * i / 10.0) * LIDAR_RANGE,\n",
    "            )\n",
    "            self.world.RayCast(self.lidar[i], self.lidar[i].p1, self.lidar[i].p2)\n",
    "\n",
    "        state = [\n",
    "            self.hull.angle,  # Normal angles up to 0.5 here, but sure more is possible.\n",
    "            2.0 * self.hull.angularVelocity / FPS,\n",
    "            0.3 * vel.x * (VIEWPORT_W / SCALE) / FPS,  # Normalized to get -1..1 range\n",
    "            0.3 * vel.y * (VIEWPORT_H / SCALE) / FPS,\n",
    "            self.joints[0].angle,\n",
    "            # This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)\n",
    "            self.joints[0].speed / SPEED_HIP,\n",
    "            self.joints[1].angle + 1.0,\n",
    "            self.joints[1].speed / SPEED_KNEE,\n",
    "            1.0 if self.legs[1].ground_contact else 0.0,\n",
    "            self.joints[2].angle,\n",
    "            self.joints[2].speed / SPEED_HIP,\n",
    "            self.joints[3].angle + 1.0,\n",
    "            self.joints[3].speed / SPEED_KNEE,\n",
    "            1.0 if self.legs[3].ground_contact else 0.0,\n",
    "        ]\n",
    "        state += [l.fraction for l in self.lidar]\n",
    "        assert len(state) == 24\n",
    "\n",
    "        self.scroll = pos.x - VIEWPORT_W / SCALE / 5\n",
    "\n",
    "\n",
    "\n",
    "        #ALTERAR PENALIZAÇÃO   <-AQUI\n",
    "        shaping = (\n",
    "            130 * pos[0] / SCALE\n",
    "        )  # moving forward is a way to receive reward (normalized to get 300 on completion)\n",
    "        shaping -= 5.0 * abs(\n",
    "            state[0]\n",
    "        )  # keep head straight, other than that and falling, any behavior is unpunished\n",
    "\n",
    "        reward = 0\n",
    "        if self.prev_shaping is not None:\n",
    "            reward = shaping - self.prev_shaping\n",
    "        self.prev_shaping = shaping\n",
    "\n",
    "        for a in action:\n",
    "            reward -= 0.00035 * MOTORS_TORQUE * np.clip(np.abs(a), 0, 1)\n",
    "            # normalized to about -50.0 using heuristic, more optimal agent should spend less\n",
    "\n",
    "        terminated = False\n",
    "        if self.game_over or pos[0] < 0:\n",
    "            reward = -100\n",
    "            terminated = True\n",
    "        if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:\n",
    "            terminated = True\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(state, dtype=np.float32), reward, terminated, False, {}\n",
    "    \n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            assert self.spec is not None\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym.make(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "            from pygame import gfxdraw\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[box2d]`\"\n",
    "            ) from e\n",
    "\n",
    "        if self.screen is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.screen = pygame.display.set_mode((VIEWPORT_W, VIEWPORT_H))\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.surf = pygame.Surface(\n",
    "            (VIEWPORT_W + max(0.0, self.scroll) * SCALE, VIEWPORT_H)\n",
    "        )\n",
    "\n",
    "        pygame.transform.scale(self.surf, (SCALE, SCALE))\n",
    "\n",
    "        pygame.draw.polygon(\n",
    "            self.surf,\n",
    "            color=(215, 215, 255),\n",
    "            points=[\n",
    "                (self.scroll * SCALE, 0),\n",
    "                (self.scroll * SCALE + VIEWPORT_W, 0),\n",
    "                (self.scroll * SCALE + VIEWPORT_W, VIEWPORT_H),\n",
    "                (self.scroll * SCALE, VIEWPORT_H),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        for poly, x1, x2 in self.cloud_poly:\n",
    "            if x2 < self.scroll / 2:\n",
    "                continue\n",
    "            if x1 > self.scroll / 2 + VIEWPORT_W / SCALE:\n",
    "                continue\n",
    "            pygame.draw.polygon(\n",
    "                self.surf,\n",
    "                color=(255, 255, 255),\n",
    "                points=[\n",
    "                    (p[0] * SCALE + self.scroll * SCALE / 2, p[1] * SCALE) for p in poly\n",
    "                ],\n",
    "            )\n",
    "            gfxdraw.aapolygon(\n",
    "                self.surf,\n",
    "                [(p[0] * SCALE + self.scroll * SCALE / 2, p[1] * SCALE) for p in poly],\n",
    "                (255, 255, 255),\n",
    "            )\n",
    "        for poly, color in self.terrain_poly:\n",
    "            if poly[1][0] < self.scroll:\n",
    "                continue\n",
    "            if poly[0][0] > self.scroll + VIEWPORT_W / SCALE:\n",
    "                continue\n",
    "            scaled_poly = []\n",
    "            for coord in poly:\n",
    "                scaled_poly.append([coord[0] * SCALE, coord[1] * SCALE])\n",
    "            pygame.draw.polygon(self.surf, color=color, points=scaled_poly)\n",
    "            gfxdraw.aapolygon(self.surf, scaled_poly, color)\n",
    "\n",
    "        self.lidar_render = (self.lidar_render + 1) % 100\n",
    "        i = self.lidar_render\n",
    "        if i < 2 * len(self.lidar):\n",
    "            single_lidar = (\n",
    "                self.lidar[i]\n",
    "                if i < len(self.lidar)\n",
    "                else self.lidar[len(self.lidar) - i - 1]\n",
    "            )\n",
    "            if hasattr(single_lidar, \"p1\") and hasattr(single_lidar, \"p2\"):\n",
    "                pygame.draw.line(\n",
    "                    self.surf,\n",
    "                    color=(255, 0, 0),\n",
    "                    start_pos=(single_lidar.p1[0] * SCALE, single_lidar.p1[1] * SCALE),\n",
    "                    end_pos=(single_lidar.p2[0] * SCALE, single_lidar.p2[1] * SCALE),\n",
    "                    width=1,\n",
    "                )\n",
    "\n",
    "        for obj in self.drawlist:\n",
    "            for f in obj.fixtures:\n",
    "                trans = f.body.transform\n",
    "                if type(f.shape) is circleShape:\n",
    "                    pygame.draw.circle(\n",
    "                        self.surf,\n",
    "                        color=obj.color1,\n",
    "                        center=trans * f.shape.pos * SCALE,\n",
    "                        radius=f.shape.radius * SCALE,\n",
    "                    )\n",
    "                    pygame.draw.circle(\n",
    "                        self.surf,\n",
    "                        color=obj.color2,\n",
    "                        center=trans * f.shape.pos * SCALE,\n",
    "                        radius=f.shape.radius * SCALE,\n",
    "                    )\n",
    "                else:\n",
    "                    path = [trans * v * SCALE for v in f.shape.vertices]\n",
    "                    if len(path) > 2:\n",
    "                        pygame.draw.polygon(self.surf, color=obj.color1, points=path)\n",
    "                        gfxdraw.aapolygon(self.surf, path, obj.color1)\n",
    "                        path.append(path[0])\n",
    "                        pygame.draw.polygon(\n",
    "                            self.surf, color=obj.color2, points=path, width=1\n",
    "                        )\n",
    "                        gfxdraw.aapolygon(self.surf, path, obj.color2)\n",
    "                    else:\n",
    "                        pygame.draw.aaline(\n",
    "                            self.surf,\n",
    "                            start_pos=path[0],\n",
    "                            end_pos=path[1],\n",
    "                            color=obj.color1,\n",
    "                        )\n",
    "\n",
    "        flagy1 = TERRAIN_HEIGHT * SCALE\n",
    "        flagy2 = flagy1 + 50\n",
    "        x = TERRAIN_STEP * 3 * SCALE\n",
    "        pygame.draw.aaline(\n",
    "            self.surf, color=(0, 0, 0), start_pos=(x, flagy1), end_pos=(x, flagy2)\n",
    "        )\n",
    "        f = [\n",
    "            (x, flagy2),\n",
    "            (x, flagy2 - 10),\n",
    "            (x + 25, flagy2 - 5),\n",
    "        ]\n",
    "        pygame.draw.polygon(self.surf, color=(230, 51, 0), points=f)\n",
    "        pygame.draw.lines(\n",
    "            self.surf, color=(0, 0, 0), points=f + [f[0]], width=1, closed=False\n",
    "        )\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            assert self.screen is not None\n",
    "            self.screen.blit(self.surf, (-self.scroll * SCALE, 0))\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.surf)), axes=(1, 0, 2)\n",
    "            )[:, -VIEWPORT_W:]\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False\n",
    "\n",
    "\n",
    "class BipedalWalkerHardcore:\n",
    "    def __init__(self):\n",
    "        raise error.Error(\n",
    "            \"Error initializing BipedalWalkerHardcore Environment.\\n\"\n",
    "            \"Currently, we do not support initializing this mode of environment by calling the class directly.\\n\"\n",
    "            \"To use this environment, instead create it by specifying the hardcore keyword in gym.make, i.e.\\n\"\n",
    "            'gym.make(\"BipedalWalker-v3\", hardcore=True)'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class RewardModifierWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(RewardModifierWrapper, self).__init__(env)\n",
    "\n",
    "    def step(self, action):\n",
    "        results = self.env.step(action)\n",
    "        state, reward, done, info = results[:4]  # Assume the first four values are defaults\n",
    "        # Modifying the reward \n",
    "        modified_reward = self.modify_reward(reward, state, action)\n",
    "        return (state, modified_reward, done, info) + results[4:]  # Return additional values, if any\n",
    "\n",
    "    def modify_reward(self, reward, state, action):\n",
    "        # Here you can add custom penalty logic\n",
    "        # penalidade_movimento_brusco = 0.001 #->Default: 0.001\n",
    "        # penalidade_movimento_brusco = 0.002 #->Attempt 1        \n",
    "        penalidade_movimento_brusco = 0.003 #->Attempt 2 \n",
    "        # penalidade_movimento_brusco = 0.004 #->Attempt 3\n",
    "        penalidade_movimento_brusco *= sum(np.abs(np.diff(np.append(self.env.prev_action, action))))\n",
    "\n",
    "        self.env.prev_action = action  # Stores the last action for future calculations\n",
    "        return reward - penalidade_movimento_brusco\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Heurisic: suboptimal, have no notion of balance.\n",
    "    env = BipedalWalker()\n",
    "    # env.render_mode = \"human\"\n",
    "\n",
    "    env.prev_action = np.zeros(env.action_space.shape)  # Inicializa a ação anterior\n",
    "    env = RewardModifierWrapper(env)\n",
    "    env.reset()\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    a = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    STAY_ON_ONE_LEG, PUT_OTHER_DOWN, PUSH_OFF = 1, 2, 3\n",
    "    SPEED = 0.29  # Will fall forward on higher speed\n",
    "    state = STAY_ON_ONE_LEG\n",
    "    moving_leg = 0\n",
    "    supporting_leg = 1 - moving_leg\n",
    "    SUPPORT_KNEE_ANGLE = +0.1\n",
    "    supporting_knee_angle = SUPPORT_KNEE_ANGLE\n",
    "    while True:\n",
    "        s, r, terminated, truncated, info = env.step(a)\n",
    "        total_reward += r\n",
    "        if steps % 20 == 0 or terminated or truncated:\n",
    "            print(\"\\naction \" + str([f\"{x:+0.2f}\" for x in a]))\n",
    "            print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
    "            print(\"hull \" + str([f\"{x:+0.2f}\" for x in s[0:4]]))\n",
    "            print(\"leg0 \" + str([f\"{x:+0.2f}\" for x in s[4:9]]))\n",
    "            print(\"leg1 \" + str([f\"{x:+0.2f}\" for x in s[9:14]]))\n",
    "        steps += 1\n",
    "\n",
    "        contact0 = s[8]\n",
    "        contact1 = s[13]\n",
    "        moving_s_base = 4 + 5 * moving_leg\n",
    "        supporting_s_base = 4 + 5 * supporting_leg\n",
    "\n",
    "        hip_targ = [None, None]  # -0.8 .. +1.1\n",
    "        knee_targ = [None, None]  # -0.6 .. +0.9\n",
    "        hip_todo = [0.0, 0.0]\n",
    "        knee_todo = [0.0, 0.0]\n",
    "\n",
    "        if state == STAY_ON_ONE_LEG:\n",
    "            hip_targ[moving_leg] = 1.1\n",
    "            knee_targ[moving_leg] = -0.6\n",
    "            supporting_knee_angle += 0.03\n",
    "            if s[2] > SPEED:\n",
    "                supporting_knee_angle += 0.03\n",
    "            supporting_knee_angle = min(supporting_knee_angle, SUPPORT_KNEE_ANGLE)\n",
    "            knee_targ[supporting_leg] = supporting_knee_angle\n",
    "            if s[supporting_s_base + 0] < 0.10:  # supporting leg is behind\n",
    "                state = PUT_OTHER_DOWN\n",
    "        if state == PUT_OTHER_DOWN:\n",
    "            hip_targ[moving_leg] = +0.1\n",
    "            knee_targ[moving_leg] = SUPPORT_KNEE_ANGLE\n",
    "            knee_targ[supporting_leg] = supporting_knee_angle\n",
    "            if s[moving_s_base + 4]:\n",
    "                state = PUSH_OFF\n",
    "                supporting_knee_angle = min(s[moving_s_base + 2], SUPPORT_KNEE_ANGLE)\n",
    "        if state == PUSH_OFF:\n",
    "            knee_targ[moving_leg] = supporting_knee_angle\n",
    "            knee_targ[supporting_leg] = +1.0\n",
    "            if s[supporting_s_base + 2] > 0.88 or s[2] > 1.2 * SPEED:\n",
    "                state = STAY_ON_ONE_LEG\n",
    "                moving_leg = 1 - moving_leg\n",
    "                supporting_leg = 1 - moving_leg\n",
    "\n",
    "        if hip_targ[0]:\n",
    "            hip_todo[0] = 0.9 * (hip_targ[0] - s[4]) - 0.25 * s[5]\n",
    "        if hip_targ[1]:\n",
    "            hip_todo[1] = 0.9 * (hip_targ[1] - s[9]) - 0.25 * s[10]\n",
    "        if knee_targ[0]:\n",
    "            knee_todo[0] = 4.0 * (knee_targ[0] - s[6]) - 0.25 * s[7]\n",
    "        if knee_targ[1]:\n",
    "            knee_todo[1] = 4.0 * (knee_targ[1] - s[11]) - 0.25 * s[12]\n",
    "\n",
    "        hip_todo[0] -= 0.9 * (0 - s[0]) - 1.5 * s[1]  # PID to keep head strait\n",
    "        hip_todo[1] -= 0.9 * (0 - s[0]) - 1.5 * s[1]\n",
    "        knee_todo[0] -= 15.0 * s[3]  # vertical speed, to damp oscillations\n",
    "        knee_todo[1] -= 15.0 * s[3]\n",
    "\n",
    "        a[0] = hip_todo[0]\n",
    "        a[1] = knee_todo[0]\n",
    "        a[2] = hip_todo[1]\n",
    "        a[3] = knee_todo[1]\n",
    "        a = np.clip(0.5 * a, -1.0, 1.0)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Model: PPO - *Trainning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70.8     |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 3959     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3072        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008137861 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.00743     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2872        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426407 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -0.246      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 0.691       |\n",
      "-----------------------------------------\n",
      "i . 0\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70.8     |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 3976     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3063        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011939546 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 0.497       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2880        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011325914 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0603      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "i . 1\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70.8     |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 4214     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 14336    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3229        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010183363 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 0.0928      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2985        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010863969 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0166      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 0.0822      |\n",
      "-----------------------------------------\n",
      "i . 2\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70.8     |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 4342     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.59e+03    |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3182        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013146613 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.59e+03     |\n",
      "|    ep_rew_mean          | -359         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2996         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076487856 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.28        |\n",
      "|    explained_variance   | -0.363       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "i . 3\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.59e+03 |\n",
      "|    ep_rew_mean     | -359     |\n",
      "| time/              |          |\n",
      "|    fps             | 4392     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 26624    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.59e+03   |\n",
      "|    ep_rew_mean          | -359       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3330       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01111326 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.2       |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0363     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 0.883      |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.59e+03    |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3083        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008323024 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "i . 4\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.5e+03  |\n",
      "|    ep_rew_mean     | -338     |\n",
      "| time/              |          |\n",
      "|    fps             | 4137     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.5e+03      |\n",
      "|    ep_rew_mean          | -338         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3089         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029821843 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | -0.033       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    std                  | 0.876        |\n",
      "|    value_loss           | 91.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.5e+03    |\n",
      "|    ep_rew_mean          | -338       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2909       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01003323 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.12      |\n",
      "|    explained_variance   | -0.476     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 0.865      |\n",
      "|    value_loss           | 0.337      |\n",
      "----------------------------------------\n",
      "i . 5\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.5e+03  |\n",
      "|    ep_rew_mean     | -338     |\n",
      "| time/              |          |\n",
      "|    fps             | 4385     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 38912    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55e+03    |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3244        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009084934 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55e+03    |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2998        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007464905 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.344       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "i . 6\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.55e+03 |\n",
      "|    ep_rew_mean     | -316     |\n",
      "| time/              |          |\n",
      "|    fps             | 4375     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 45056    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.52e+03    |\n",
      "|    ep_rew_mean          | -294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3244        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010380797 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    std                  | 0.835       |\n",
      "|    value_loss           | 0.417       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.52e+03   |\n",
      "|    ep_rew_mean          | -294       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3011       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01070566 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.94      |\n",
      "|    explained_variance   | -0.0476    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.54       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00942   |\n",
      "|    std                  | 0.833      |\n",
      "|    value_loss           | 30.6       |\n",
      "----------------------------------------\n",
      "i . 7\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.35e+03 |\n",
      "|    ep_rew_mean     | -275     |\n",
      "| time/              |          |\n",
      "|    fps             | 4338     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | -240        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3296        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004542687 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.77e+03     |\n",
      "|    ep_rew_mean          | -240         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3066         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053673387 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.9         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 89.9         |\n",
      "------------------------------------------\n",
      "i . 8\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    fps             | 4353     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 57344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | -221        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3297        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010377523 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    std                  | 0.808       |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.61e+03    |\n",
      "|    ep_rew_mean          | -204        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3025        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012255816 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.302       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.794       |\n",
      "|    value_loss           | 0.731       |\n",
      "-----------------------------------------\n",
      "i . 9\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    fps             | 4255     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.53e+03     |\n",
      "|    ep_rew_mean          | -193         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3205         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056345696 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.73        |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.38         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | -186        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2983        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372764 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.781       |\n",
      "|    value_loss           | 0.418       |\n",
      "-----------------------------------------\n",
      "i . 10\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | -174     |\n",
      "| time/              |          |\n",
      "|    fps             | 4427     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 69632    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.24e+03    |\n",
      "|    ep_rew_mean          | -158        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3289        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010880192 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.192       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.773       |\n",
      "|    value_loss           | 0.684       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3058        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003391632 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.772       |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "i . 11\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | -143     |\n",
      "| time/              |          |\n",
      "|    fps             | 4401     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 75776    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.78e+03     |\n",
      "|    ep_rew_mean          | -140         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3341         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061034504 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.77e+03     |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3091         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058705444 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    std                  | 0.772        |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "i . 12\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.77e+03 |\n",
      "|    ep_rew_mean     | -133     |\n",
      "| time/              |          |\n",
      "|    fps             | 4462     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -132        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3334        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009388678 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.772       |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3063        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683578 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    std                  | 0.77        |\n",
      "|    value_loss           | 9.03        |\n",
      "-----------------------------------------\n",
      "i . 13\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | -121     |\n",
      "| time/              |          |\n",
      "|    fps             | 4353     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 88064    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.76e+03   |\n",
      "|    ep_rew_mean          | -116       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3331       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00857733 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.59      |\n",
      "|    explained_variance   | 0.894      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.829      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00792   |\n",
      "|    std                  | 0.765      |\n",
      "|    value_loss           | 5.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3068        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012511982 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 0.563       |\n",
      "-----------------------------------------\n",
      "i . 14\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    fps             | 4355     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3343        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007475894 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    std                  | 0.748       |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3102        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009491826 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    std                  | 0.743       |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "i . 15\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 4359     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -97.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3312        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308187 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.46       |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    std                  | 0.737       |\n",
      "|    value_loss           | 7.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -96.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3047        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008693197 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.52        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "i . 16\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.69e+03 |\n",
      "|    ep_rew_mean     | -95.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 4342     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -91.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3255        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014611314 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.731       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -88.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2968        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019198233 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.339       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.718       |\n",
      "|    value_loss           | 0.751       |\n",
      "-----------------------------------------\n",
      "i . 17\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | -84.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 4331     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -80.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3315        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014285976 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 0.754       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -79.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3055        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014198448 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 0.531       |\n",
      "-----------------------------------------\n",
      "i . 18\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | -78      |\n",
      "| time/              |          |\n",
      "|    fps             | 4442     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 118784   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -74.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3324        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010666747 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.65        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    std                  | 0.684       |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -70.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3066         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146655375 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.16        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 6.95         |\n",
      "------------------------------------------\n",
      "i . 19\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.71e+03 |\n",
      "|    ep_rew_mean     | -67.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 4231     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | -65.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3243         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139151085 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.12        |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.161        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    std                  | 0.677        |\n",
      "|    value_loss           | 0.681        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -64.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2970        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009442281 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.919       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    std                  | 0.677       |\n",
      "|    value_loss           | 9.47        |\n",
      "-----------------------------------------\n",
      "i . 20\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.64e+03 |\n",
      "|    ep_rew_mean     | -64.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 4332     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -61.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3215        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008823302 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    std                  | 0.675       |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -58.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3022        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530602 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.36        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "i . 21\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | -56      |\n",
      "| time/              |          |\n",
      "|    fps             | 4377     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 137216   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -56.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3267        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014010318 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | -0.0747     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    std                  | 0.673       |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -54.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3008         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066118333 |\n",
      "|    clip_fraction        | 0.071        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00813     |\n",
      "|    std                  | 0.674        |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "i . 22\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | -51.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 4456     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 143360   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.57e+03   |\n",
      "|    ep_rew_mean          | -50.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3361       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901431 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.08      |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.9        |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.00456   |\n",
      "|    std                  | 0.671      |\n",
      "|    value_loss           | 9.63       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -48.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3090        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006903694 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.91        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.671       |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "i . 23\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | -48.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 4463     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 149504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+03   |\n",
      "|    ep_rew_mean          | -46.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3328       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00964847 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.54       |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.00619   |\n",
      "|    std                  | 0.674      |\n",
      "|    value_loss           | 8.83       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -44.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3088        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012754293 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.494       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    std                  | 0.666       |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "i . 24\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | -43.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 4438     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -41.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3348        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010510286 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.98        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    std                  | 0.664       |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -40.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3101        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010460543 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    std                  | 0.666       |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "i . 25\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | -21.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 4427     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3351        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014766311 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 7.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -13.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3100        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009537061 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "i . 26\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | -11      |\n",
      "| time/              |          |\n",
      "|    fps             | 4176     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 167936   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.37e+03  |\n",
      "|    ep_rew_mean          | -8.24     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 3195      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 169984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0188039 |\n",
      "|    clip_fraction        | 0.223     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.02     |\n",
      "|    explained_variance   | 0.666     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.31      |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -0.00713  |\n",
      "|    std                  | 0.663     |\n",
      "|    value_loss           | 0.698     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -0.351      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2994        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014687179 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.654       |\n",
      "|    value_loss           | 0.562       |\n",
      "-----------------------------------------\n",
      "i . 27\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.28e+03 |\n",
      "|    ep_rew_mean     | 3.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 4391     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 174080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 6.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3317        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012314095 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 0.634       |\n",
      "|    value_loss           | 0.624       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 8.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3039        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040144 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.628       |\n",
      "|    value_loss           | 0.709       |\n",
      "-----------------------------------------\n",
      "i . 28\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.26e+03 |\n",
      "|    ep_rew_mean     | 10.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 4398     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | 12.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3179         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045030545 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.16         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    std                  | 0.627        |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2884        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008254526 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    std                  | 0.625       |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "i . 29\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.25e+03 |\n",
      "|    ep_rew_mean     | 16.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 4455     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 19.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3309        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018308206 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.643       |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    std                  | 0.617       |\n",
      "|    value_loss           | 0.711       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 21.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3055        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012008625 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    std                  | 0.615       |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "i . 30\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.25e+03 |\n",
      "|    ep_rew_mean     | 23.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 4398     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 23.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3306        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015571486 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.608       |\n",
      "|    value_loss           | 0.841       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 26.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3048        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014922323 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.578       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.609       |\n",
      "|    value_loss           | 6.2         |\n",
      "-----------------------------------------\n",
      "i . 31\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.26e+03 |\n",
      "|    ep_rew_mean     | 29.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 4395     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 198656   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 33.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3328        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012288356 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    std                  | 0.591       |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 35.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3076        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012643037 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    std                  | 0.589       |\n",
      "|    value_loss           | 6.85        |\n",
      "-----------------------------------------\n",
      "i . 32\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.32e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 4379     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.31e+03     |\n",
      "|    ep_rew_mean          | 39           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3281         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058961483 |\n",
      "|    clip_fraction        | 0.0654       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.54        |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 0.59         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 39.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2915        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008123535 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "i . 33\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | 40.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 4447     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 45.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3321        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010588094 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.966       |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3046        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013811953 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 0.587       |\n",
      "|    value_loss           | 3.85        |\n",
      "-----------------------------------------\n",
      "i . 34\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.32e+03 |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 4236     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 49.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3274        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014762199 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.577       |\n",
      "|    value_loss           | 0.633       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3015        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014054114 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.57        |\n",
      "|    value_loss           | 0.831       |\n",
      "-----------------------------------------\n",
      "i . 35\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 4281     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 223232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 52.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3150        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016015548 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.289       |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    std                  | 0.569       |\n",
      "|    value_loss           | 0.828       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2951        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015949722 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.566       |\n",
      "|    value_loss           | 0.615       |\n",
      "-----------------------------------------\n",
      "i . 36\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 58.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 4350     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 229376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 61          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3307        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014337607 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 0.716       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 61.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3074        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013049623 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.398       |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 0.565       |\n",
      "|    value_loss           | 0.803       |\n",
      "-----------------------------------------\n",
      "i . 37\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | 64.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 4280     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 235520   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 65.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3258        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012241455 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.482       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    std                  | 0.559       |\n",
      "|    value_loss           | 3.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 65.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3033        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010433923 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    std                  | 0.559       |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "i . 38\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 66.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 4241     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 66.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3155        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012893926 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.55        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 66.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2952        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015852243 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.223       |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    std                  | 0.547       |\n",
      "|    value_loss           | 0.932       |\n",
      "-----------------------------------------\n",
      "i . 39\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | 67.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 4442     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.3e+03    |\n",
      "|    ep_rew_mean          | 69.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3345       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01034514 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.22      |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.00796   |\n",
      "|    std                  | 0.545      |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 68          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3048        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019065496 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.522       |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.549       |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "i . 40\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | 68.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 4338     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 253952   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 71.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3199        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016374659 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.541       |\n",
      "|    value_loss           | 0.696       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 73.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3009        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013697927 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.539       |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "i . 41\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 76.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 4363     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.32e+03   |\n",
      "|    ep_rew_mean          | 79.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3317       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01235886 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.15      |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.58       |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | -0.00614   |\n",
      "|    std                  | 0.537      |\n",
      "|    value_loss           | 10.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 82.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3070        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580161 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | -0.313      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    std                  | 0.538       |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "i . 42\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 82.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 4433     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 266240   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3324        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014274212 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.715       |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 1.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 85.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3080        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015378263 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0638      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.533       |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "i . 43\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 88.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 4423     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 272384   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3356        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010552665 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.478       |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3090        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015444581 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "i . 44\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 87.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 4413     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 89.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3308        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010619294 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.485       |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 0.538       |\n",
      "|    value_loss           | 5.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.34e+03   |\n",
      "|    ep_rew_mean          | 90.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3076       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01333939 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.11      |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.46       |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.0057    |\n",
      "|    std                  | 0.528      |\n",
      "|    value_loss           | 1.26       |\n",
      "----------------------------------------\n",
      "i . 45\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 93       |\n",
      "| time/              |          |\n",
      "|    fps             | 4445     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 284672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 91.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3359        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014603934 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.625       |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.529       |\n",
      "|    value_loss           | 0.988       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3099        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011196656 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    std                  | 0.527       |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "i . 46\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.32e+03 |\n",
      "|    ep_rew_mean     | 91.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 4451     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 89.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3360        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906882 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.05       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    std                  | 0.526       |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3111        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016794946 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "i . 47\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 95.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 4483     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 296960   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.3e+03    |\n",
      "|    ep_rew_mean          | 93.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3377       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02466756 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.02      |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.094      |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 0.52       |\n",
      "|    value_loss           | 1.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 93.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3122        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095572 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 5.05        |\n",
      "-----------------------------------------\n",
      "i . 48\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | 94       |\n",
      "| time/              |          |\n",
      "|    fps             | 4475     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3330        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015231842 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.608       |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 95.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3085        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009092829 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 9.38        |\n",
      "-----------------------------------------\n",
      "i . 49\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 97.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 4426     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 309248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3370        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013654866 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.933       |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3111        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012562786 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "i . 50\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 104      |\n",
      "| time/              |          |\n",
      "|    fps             | 4492     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 315392   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 106         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3373        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017688707 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 0.913       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3119         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123324115 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.83         |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.00882     |\n",
      "|    std                  | 0.523        |\n",
      "|    value_loss           | 11.5         |\n",
      "------------------------------------------\n",
      "i . 51\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    fps             | 4442     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3302        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013358034 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3067        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017895004 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.568       |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 7.38        |\n",
      "-----------------------------------------\n",
      "i . 52\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 4330     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3330        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016443767 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.293       |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.521       |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3091        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017207202 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0837      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 0.97        |\n",
      "-----------------------------------------\n",
      "i . 53\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 4456     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 333824   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3367        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014495976 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3119        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017940708 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 0.612       |\n",
      "-----------------------------------------\n",
      "i . 54\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    fps             | 4476     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 339968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 119         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3368        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010945485 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.895       |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 4.84        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.38e+03   |\n",
      "|    ep_rew_mean          | 122        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3091       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02003263 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.94      |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.436      |\n",
      "|    n_updates            | 1670       |\n",
      "|    policy_gradient_loss | -0.00945   |\n",
      "|    std                  | 0.513      |\n",
      "|    value_loss           | 1.11       |\n",
      "----------------------------------------\n",
      "i . 55\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    fps             | 4478     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 346112   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3381        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014925788 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 0.865       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3123        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011255631 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 0.508       |\n",
      "|    value_loss           | 8.57        |\n",
      "-----------------------------------------\n",
      "i . 56\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    fps             | 4434     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 126         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3375        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012466099 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 7.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 122         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3118        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890404 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.542       |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "i . 57\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    fps             | 4441     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 358400   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.36e+03   |\n",
      "|    ep_rew_mean          | 123        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3373       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 360448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943642 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 1750       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 0.504      |\n",
      "|    value_loss           | 2.25       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 121         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3094        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021527395 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 0.5         |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "i . 58\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    fps             | 4504     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 364544   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 119         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3382        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011688574 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 6.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 121         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3123        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013349757 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.06        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    std                  | 0.5         |\n",
      "|    value_loss           | 9.49        |\n",
      "-----------------------------------------\n",
      "i . 59\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    fps             | 4462     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 125         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3367        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014203515 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 0.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3108        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021362055 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 0.489       |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "i . 60\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    fps             | 4465     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 376832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3332        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017529191 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 0.667       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.35e+03   |\n",
      "|    ep_rew_mean          | 127        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3092       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02011795 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.7       |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.193      |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    std                  | 0.487      |\n",
      "|    value_loss           | 0.594      |\n",
      "----------------------------------------\n",
      "i . 61\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.37e+03 |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    fps             | 4443     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 382976   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 132         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3327        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020550169 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0952      |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.486       |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 131         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3079        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022234738 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.509       |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 0.487       |\n",
      "|    value_loss           | 0.89        |\n",
      "-----------------------------------------\n",
      "i . 62\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    fps             | 4379     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 389120   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.35e+03  |\n",
      "|    ep_rew_mean          | 129       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 3338      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 391168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0197578 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.71     |\n",
      "|    explained_variance   | 0.256     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.456     |\n",
      "|    n_updates            | 1900      |\n",
      "|    policy_gradient_loss | -0.0111   |\n",
      "|    std                  | 0.489     |\n",
      "|    value_loss           | 2.7       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 129         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3100        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015470538 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.487       |\n",
      "|    value_loss           | 7.61        |\n",
      "-----------------------------------------\n",
      "i . 63\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    fps             | 4454     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 395264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 129         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3357        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024646606 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3112        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013448075 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.928       |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    std                  | 0.484       |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n",
      "i . 64\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    fps             | 4456     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3379        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017015403 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.474       |\n",
      "|    value_loss           | 0.929       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3122        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022003923 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0787      |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 0.475       |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "i . 65\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    fps             | 4341     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 407552   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3190        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016076988 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    std                  | 0.474       |\n",
      "|    value_loss           | 0.849       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 138         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2973        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013323746 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "i . 66\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.37e+03 |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    fps             | 4420     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 413696   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.38e+03   |\n",
      "|    ep_rew_mean          | 142        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3205       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 415744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01323235 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.57      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.94       |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | -0.00717   |\n",
      "|    std                  | 0.473      |\n",
      "|    value_loss           | 2.68       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 142         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2989        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011108857 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.93        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    std                  | 0.473       |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "i . 67\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.37e+03 |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    fps             | 4457     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 419840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 138         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3343        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015652481 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.544       |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    std                  | 0.471       |\n",
      "|    value_loss           | 0.707       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.37e+03   |\n",
      "|    ep_rew_mean          | 143        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3068       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00998369 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.55      |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.03       |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | -0.0076    |\n",
      "|    std                  | 0.471      |\n",
      "|    value_loss           | 7.83       |\n",
      "----------------------------------------\n",
      "i . 68\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    fps             | 4455     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 425984   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3319        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015345994 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    std                  | 0.464       |\n",
      "|    value_loss           | 0.858       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3069        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015393516 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.533       |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    std                  | 0.463       |\n",
      "|    value_loss           | 9.21        |\n",
      "-----------------------------------------\n",
      "i . 69\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.41e+03 |\n",
      "|    ep_rew_mean     | 153      |\n",
      "| time/              |          |\n",
      "|    fps             | 4393     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 432128   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.42e+03     |\n",
      "|    ep_rew_mean          | 155          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3298         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 434176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124794375 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.179        |\n",
      "|    n_updates            | 2110         |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 0.985        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3011        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024795568 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.457       |\n",
      "|    value_loss           | 0.822       |\n",
      "-----------------------------------------\n",
      "i . 70\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.42e+03 |\n",
      "|    ep_rew_mean     | 156      |\n",
      "| time/              |          |\n",
      "|    fps             | 4375     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 438272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3290        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019549128 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3045        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015125286 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.36       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0326      |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 0.449       |\n",
      "|    value_loss           | 0.7         |\n",
      "-----------------------------------------\n",
      "i . 71\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    fps             | 4466     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 444416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3325        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019155296 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 0.819       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3086        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011533948 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 8.81        |\n",
      "-----------------------------------------\n",
      "i . 72\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    fps             | 4500     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.43e+03  |\n",
      "|    ep_rew_mean          | 161       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 3337      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 452608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0140487 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.22     |\n",
      "|    explained_variance   | 0.915     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.47      |\n",
      "|    n_updates            | 2200      |\n",
      "|    policy_gradient_loss | -0.0043   |\n",
      "|    std                  | 0.435     |\n",
      "|    value_loss           | 11.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3099        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011877619 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    std                  | 0.435       |\n",
      "|    value_loss           | 8.16        |\n",
      "-----------------------------------------\n",
      "i . 73\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    fps             | 4477     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 456704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3383        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022470247 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    std                  | 0.427       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3121        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011644863 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.426       |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "i . 74\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    fps             | 4485     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 462848   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | 162        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3359       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01582687 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.14      |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 0.426      |\n",
      "|    value_loss           | 2.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3077        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022486702 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 0.424       |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "i . 75\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    fps             | 4307     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 468992   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3325        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017710075 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.725       |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    std                  | 0.423       |\n",
      "|    value_loss           | 4.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3091        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018534094 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.426       |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "i . 76\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    fps             | 4494     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 475136   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3386        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014392604 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 0.427       |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3129        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017219443 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0804      |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 0.426       |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "i . 77\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    fps             | 4474     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 481280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3339        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018927481 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    std                  | 0.422       |\n",
      "|    value_loss           | 0.913       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.39e+03   |\n",
      "|    ep_rew_mean          | 163        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3097       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 485376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01741418 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.1       |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.06       |\n",
      "|    n_updates            | 2360       |\n",
      "|    policy_gradient_loss | -0.00675   |\n",
      "|    std                  | 0.425      |\n",
      "|    value_loss           | 1.58       |\n",
      "----------------------------------------\n",
      "i . 78\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    fps             | 4505     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 487424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3381        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011133633 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.56        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    std                  | 0.426       |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3127        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015196359 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.426       |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "i . 79\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 168      |\n",
      "| time/              |          |\n",
      "|    fps             | 4502     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 493568   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3398        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018127196 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.96        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3122        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019556995 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 0.585       |\n",
      "-----------------------------------------\n",
      "i . 80\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    fps             | 4489     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 499712   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3196        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020433176 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.415       |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2972        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018340945 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 0.417       |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "i . 81\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 177      |\n",
      "| time/              |          |\n",
      "|    fps             | 4466     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 505856   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | 173        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3379       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00821008 |\n",
      "|    clip_fraction        | 0.0906     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.04      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.66       |\n",
      "|    n_updates            | 2470       |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    std                  | 0.419      |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3100        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009813538 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "i . 82\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 171      |\n",
      "| time/              |          |\n",
      "|    fps             | 4359     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.4e+03    |\n",
      "|    ep_rew_mean          | 171        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3306       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 514048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01863163 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.06      |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.125      |\n",
      "|    n_updates            | 2500       |\n",
      "|    policy_gradient_loss | -0.00773   |\n",
      "|    std                  | 0.422      |\n",
      "|    value_loss           | 1.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3083        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021795336 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    std                  | 0.417       |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "i . 83\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | 170      |\n",
      "| time/              |          |\n",
      "|    fps             | 4459     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 518144   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3385        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017339252 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    std                  | 0.415       |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3125        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013841367 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.65        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 0.413       |\n",
      "|    value_loss           | 5.61        |\n",
      "-----------------------------------------\n",
      "i . 84\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | 170      |\n",
      "| time/              |          |\n",
      "|    fps             | 4357     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 524288   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.39e+03   |\n",
      "|    ep_rew_mean          | 170        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3248       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 526336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01704014 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.98      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    std                  | 0.413      |\n",
      "|    value_loss           | 3.55       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3004        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011929251 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    std                  | 0.413       |\n",
      "|    value_loss           | 7.61        |\n",
      "-----------------------------------------\n",
      "i . 85\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    fps             | 4461     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 530432   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 174         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3346        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014988024 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.193      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.636       |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    std                  | 0.405       |\n",
      "|    value_loss           | 4.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3087        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023121182 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.907       |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.403       |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "i . 86\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | 170      |\n",
      "| time/              |          |\n",
      "|    fps             | 4486     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 536576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3383        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012006087 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3129        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013025435 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 7.58        |\n",
      "-----------------------------------------\n",
      "i . 87\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    fps             | 4536     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 542720   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3391        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019197918 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    std                  | 0.392       |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3115        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022756707 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "i . 88\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    fps             | 4407     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 548864   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.36e+03   |\n",
      "|    ep_rew_mean          | 168        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3350       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 550912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02115763 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.69      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.115      |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.00671   |\n",
      "|    std                  | 0.382      |\n",
      "|    value_loss           | 0.824      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3111        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014313938 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 5.48        |\n",
      "-----------------------------------------\n",
      "i . 89\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.37e+03 |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    fps             | 4478     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 555008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3379        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026185062 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0786      |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.373       |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3124        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013349779 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    std                  | 0.374       |\n",
      "|    value_loss           | 7.75        |\n",
      "-----------------------------------------\n",
      "i . 90\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | 165      |\n",
      "| time/              |          |\n",
      "|    fps             | 4437     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3365        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015529434 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.95        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.374       |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3118        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030264238 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    std                  | 0.371       |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "i . 91\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    fps             | 4489     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 567296   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.32e+03   |\n",
      "|    ep_rew_mean          | 164        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3385       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02637748 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.176      |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 0.369      |\n",
      "|    value_loss           | 1.39       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.32e+03   |\n",
      "|    ep_rew_mean          | 164        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3130       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 571392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01503956 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.623      |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | -0.00977   |\n",
      "|    std                  | 0.369      |\n",
      "|    value_loss           | 7.24       |\n",
      "----------------------------------------\n",
      "i . 92\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    fps             | 4463     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 573440   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3377        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017049491 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.367       |\n",
      "|    value_loss           | 6.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3121        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016654193 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.366       |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "i . 93\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    fps             | 4486     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 579584   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3364        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020951685 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.796       |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3110        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020499978 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.314       |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "i . 94\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.32e+03 |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    fps             | 4491     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 585728   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3379        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021890104 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3119        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024054985 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "i . 95\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    fps             | 4403     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 591872   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3356        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017771829 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3084        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021906743 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "i . 96\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | 172      |\n",
      "| time/              |          |\n",
      "|    fps             | 4470     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 598016   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3392        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019057043 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.575       |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.35e+03   |\n",
      "|    ep_rew_mean          | 172        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3129       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 602112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694501 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.543      |\n",
      "|    n_updates            | 2930       |\n",
      "|    policy_gradient_loss | -0.00872   |\n",
      "|    std                  | 0.357      |\n",
      "|    value_loss           | 1.61       |\n",
      "----------------------------------------\n",
      "i . 97\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | 172      |\n",
      "| time/              |          |\n",
      "|    fps             | 4501     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 604160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3392        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021742972 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.383       |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.358       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3130        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017672304 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.357       |\n",
      "|    value_loss           | 0.94        |\n",
      "-----------------------------------------\n",
      "i . 98\n",
      "Logging to logdir/PPO_wrapper_attempt3_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.35e+03 |\n",
      "|    ep_rew_mean     | 172      |\n",
      "| time/              |          |\n",
      "|    fps             | 4510     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 173         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3380        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025451647 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 0.355       |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3116        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021807864 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.35        |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "i . 99\n"
     ]
    }
   ],
   "source": [
    "models_dir = \"models/PPO/wrapper_best\"\n",
    "logdir = \"logs\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log='logdir')\n",
    "\n",
    "# TIMESTEPS = 5000# 50mil of 5 mil by 5 mil\n",
    "TIMESTEPS = 50000 #10M of 50 by 50 mil\n",
    "\n",
    "for i in range(200):    #200 iterações de 50mil = 10milhões\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"PPO_wrapper_best\")\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")\n",
    "    print(\"i .\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PPO was used to find the best penalty sudden movements values, which was density=3.0, Attempt 2, with 500k timesteps. The behavior overall timesteps was represented in tensorboard graphs, for the three values. Then, the \"best\" penalty sudden movements values was trained with PPO, with 10M timesteps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
